{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as  np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284807\n",
      "284807\n"
     ]
    }
   ],
   "source": [
    "# Only use the 'Amount' and 'V1', ..., 'V28' features\n",
    "features = ['Amount'] + ['V%d' % number for number in range(1, 29)]\n",
    "\n",
    "# The target variable which we would like to predict, is the 'Class' variable\n",
    "target = 'Class'\n",
    "\n",
    "# Now create an X variable (containing the features) and an y variable (containing only the target variable)\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    \"\"\"\n",
    "    Make the distribution of the values of each variable similar by subtracting the mean and by dividing by the standard deviation.\n",
    "    \"\"\"\n",
    "    for feature in X.columns:\n",
    "        X[feature] -= X[feature].mean()\n",
    "        X[feature] /= X[feature].std()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    142158\n",
      "          1       0.88      0.61      0.72       246\n",
      "\n",
      "avg / total       1.00      1.00      1.00    142404\n",
      "\n",
      "142403\n",
      "142404\n",
      "142403\n",
      "142404\n",
      "142404\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the splitter for splitting the data in a train set and a test set\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "\n",
    "# Loop through the splits (only one)\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    # Select the train and test data\n",
    "    X_train, y_train = X.loc[train_indices], y.loc[train_indices]\n",
    "    X_test, y_test = X.loc[test_indices], y.loc[test_indices]\n",
    "    \n",
    "    # Normalize the data\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_test)\n",
    "    \n",
    "    # Fit and predict!\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # And finally: the results\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    \n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-1] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0   0.999332  0.999859  0.999596    142158\n",
      "          1   0.883041  0.613821  0.724221       246\n",
      "\n",
      "avg / total   0.999131  0.999192  0.999120    142404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99919243841465122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99764246e-01,   2.35753742e-04],\n",
       "       [  9.99510346e-01,   4.89654158e-04],\n",
       "       [  9.99519204e-01,   4.80795830e-04],\n",
       "       ..., \n",
       "       [  9.99310342e-01,   6.89657872e-04],\n",
       "       [  9.99941065e-01,   5.89345898e-05],\n",
       "       [  9.99808546e-01,   1.91453799e-04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)\n",
    "#in each array there are two eelements which signify the\n",
    "#probability that this point belongs to zero or one\n",
    "#sum of these two is one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248027    0\n",
       "159764    0\n",
       "259935    0\n",
       "111386    0\n",
       "119485    0\n",
       "273783    0\n",
       "262261    0\n",
       "115267    0\n",
       "203426    0\n",
       "145513    0\n",
       "7758      0\n",
       "259806    0\n",
       "11613     0\n",
       "258880    0\n",
       "71795     0\n",
       "217295    0\n",
       "128730    0\n",
       "260806    0\n",
       "10986     0\n",
       "38906     0\n",
       "147971    0\n",
       "116505    0\n",
       "186818    0\n",
       "241951    0\n",
       "114156    0\n",
       "262986    0\n",
       "121317    0\n",
       "12199     0\n",
       "187910    0\n",
       "113478    0\n",
       "         ..\n",
       "200843    0\n",
       "78852     0\n",
       "50673     0\n",
       "220206    0\n",
       "249360    0\n",
       "169538    0\n",
       "149552    0\n",
       "115672    0\n",
       "222605    0\n",
       "223698    0\n",
       "133073    0\n",
       "42538     0\n",
       "57784     0\n",
       "155363    0\n",
       "57356     0\n",
       "188860    0\n",
       "237444    0\n",
       "256105    0\n",
       "269098    0\n",
       "154100    0\n",
       "28646     0\n",
       "266499    0\n",
       "160565    0\n",
       "270504    0\n",
       "64398     0\n",
       "30600     0\n",
       "260037    0\n",
       "46285     0\n",
       "257086    0\n",
       "29329     0\n",
       "Name: Class, Length: 142404, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred - y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142137,     20],\n",
       "       [    87,    159]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142138,     20],\n",
       "       [    95,    151]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "0             0.999332  0.999859  0.999596  142158.0\n",
      "1             0.883041  0.613821  0.724221     246.0\n",
      "avg / total   0.999131  0.999192  0.999120  142404.0\n"
     ]
    }
   ],
   "source": [
    "df_class_report = pandas_classification_report(y_true=y_test, y_pred=y_pred)\n",
    "print(df_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_class_report.to_csv('my_csv_file.csv',  sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248027</th>\n",
       "      <td>0</td>\n",
       "      <td>1.057872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159764</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259935</th>\n",
       "      <td>0</td>\n",
       "      <td>0.927323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111386</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.395844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.577045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class   Feature\n",
       "248027      0  1.057872\n",
       "159764      0 -0.950700\n",
       "259935      0  0.927323\n",
       "111386      0 -0.395844\n",
       "119485      0  0.577045"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Class':y_pred, 'Feature' : X_test['V1'] })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Predict1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ans1.csv\", y_pred , fmt=\"%1.5f\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
